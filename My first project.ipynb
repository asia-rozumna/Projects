{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E0vqbgi9ay0H"
   },
   "source": [
    "# Yandex.Music"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fhq_eyov_Zcs"
   },
   "source": [
    "# Contents <a id='back'></a>\n",
    "\n",
    "* [Introduction](#intro)\n",
    "* [Stage 1. Data overview](#data_review)\n",
    "    * [Conclusions](#data_review_conclusions)\n",
    "* [Stage 2. Data preprocessing](#data_preprocessing)\n",
    "    * [2.1 Header style](#header_style)\n",
    "    * [2.2 Missing values](#missing_values)\n",
    "    * [2.3 Duplicates](#duplicates)\n",
    "    * [2.4 Conclusions](#data_preprocessing_conclusions)\n",
    "* [Stage 3. Testing the hypotheses](#hypotheses)\n",
    "    * [3.1 Hypothesis 1: user activity in the two cities](#activity)\n",
    "    * [3.2 Hypothesis 2: music preferences on Monday and Friday](#week)\n",
    "    * [3.3 Hypothesis 3: genre preferences in Springfield and Shelbyville](#genre)\n",
    "* [Findings](#end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VUC88oWjTJw2"
   },
   "source": [
    "## Introduction <a id='intro'></a>\n",
    "Whenever we're doing research, we need to formulate hypotheses that we can then test. Sometimes we accept these hypotheses; other times, we reject them. To make the right decisions, a business must be able to understand whether or not it's making the right assumptions.\n",
    "\n",
    "In this project, you'll compare the music preferences of the cities of Springfield and Shelbyville. You'll study real Yandex.Music data to test the hypotheses below and compare user behavior for these two cities.\n",
    "\n",
    "### Goal: \n",
    "Test three hypotheses:\n",
    "1. User activity differs depending on the day of the week and from city to city. \n",
    "2. On Monday mornings, Springfield and Shelbyville residents listen to different genres. This is also true for Friday evenings. \n",
    "3. Springfield and Shelbyville listeners have different preferences. In Springfield, they prefer pop, while Shelbyville has more rap fans.\n",
    "\n",
    "### Stages \n",
    "Data on user behavior is stored in the file `/datasets/music_project_en.csv`. There is no information about the quality of the data, so you will need to explore it before testing the hypotheses. \n",
    "\n",
    "First, you'll evaluate the quality of the data and see whether its issues are significant. Then, during data preprocessing, you will try to account for the most critical problems.\n",
    " \n",
    "Your project will consist of three stages:\n",
    " 1. Data overview\n",
    " 2. Data preprocessing\n",
    " 3. Testing the hypotheses\n",
    " \n",
    "[Back to Contents](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ml1hmfXC_Zcs"
   },
   "source": [
    "## Stage 1. Data overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import pandas, download data and have first look at it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "AXN7PHPN_Zcs"
   },
   "outputs": [],
   "source": [
    "import pandas as pd # importing pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "fFVu7vqh_Zct"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/datasets/music_project_en.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_32244\\3613732594.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/datasets/music_project_en.csv'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# reading the file and storing it to df\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    676\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 678\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 575\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    576\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    577\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    930\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 932\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    933\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    934\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1214\u001b[0m             \u001b[1;31m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1215\u001b[0m             \u001b[1;31m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1216\u001b[1;33m             self.handles = get_handle(  # type: ignore[call-overload]\n\u001b[0m\u001b[0;32m   1217\u001b[0m                 \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1218\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    784\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"b\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    785\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 786\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    787\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/datasets/music_project_en.csv'"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv('/datasets/music_project_en.csv') # reading the file and storing it to df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oWTVX3gW_Zct"
   },
   "outputs": [],
   "source": [
    "df.head(10) # obtaining the first 10 rows from the df table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DSf2kIb-_Zct"
   },
   "outputs": [],
   "source": [
    "# obtaining general information about the data in df\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TaQ2Iwbr_Zct"
   },
   "source": [
    "Our data has seven columns and 65079 rows. Each row in the table stores data on a track that was played. Some columns describe the track itself: its title, artist and genre. The rest convey information about the user: the city they come from, the time they played the track.\n",
    "The data isn't in a perfect condition, we can see such problems:\n",
    "1. Some column names are uppercase, some are lowercase.\n",
    "2. There are spaces in some column names.\n",
    "3. Some column names are not clear and should be specified.\n",
    "4. Some columns have incorrect datatype. \n",
    "5. The data contains missing values.\n",
    "\n",
    "To move forward, we need to preprocess the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3eL__vcwViOi"
   },
   "source": [
    "[Back to Contents](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SjYF6Ub9_Zct"
   },
   "source": [
    "## Stage 2. Data preprocessing <a id='data_preprocessing'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dIaKXr29_Zct"
   },
   "source": [
    "### Header style <a id='header_style'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ISlFqs5y_Zct"
   },
   "outputs": [],
   "source": [
    "df = df.rename(\n",
    "    columns={\n",
    "        '  userID' : 'user_id',\n",
    "        'Track' : 'track',\n",
    "        '  City  ' : 'city',\n",
    "        'Day' : 'day',\n",
    "    } \n",
    ") # renaming columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oKOTdF_Q_Zct"
   },
   "outputs": [],
   "source": [
    "df.columns # the list of column names in the df table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xYJk6ksJVpOl"
   },
   "source": [
    "[Back to Contents](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5ISfbcfY_Zct"
   },
   "source": [
    "### Missing values <a id='missing_values'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RskX29qr_Zct"
   },
   "outputs": [],
   "source": [
    "df.isna().sum()\n",
    "# calculating missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qubhgnlO_Zct"
   },
   "source": [
    "Columns 'track', 'artist' and 'genre' contain missing values. Not all missing values affect the research. For instance, the missing values in `track` and `artist` are not critical. But missing values in `genre` can affect the comparison of music preferences in Springfield and Shelbyville. So we them with clear markers, for example with the string 'unknown'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KplB5qWs_Zct"
   },
   "outputs": [],
   "source": [
    "columns_to_replace = ['track', 'artist', 'genre']\n",
    "for i in columns_to_replace:\n",
    "    df[i] = df[i].fillna('unknown')\n",
    "# looping over column names and replacing missing values with 'unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tq4nYRX4_Zct"
   },
   "outputs": [],
   "source": [
    "df.isna().sum() # counting missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can be absolutely sure that all the missing values have been filled it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "74ZIBmq9VrsK"
   },
   "source": [
    "[Back to Contents](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BWKRtBJ3_Zct"
   },
   "source": [
    "### Duplicates <a id='duplicates'></a>\n",
    "\n",
    "Now we'll check if there is any duplicates in our data and will drop them if we find."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "36eES_S0_Zct"
   },
   "outputs": [],
   "source": [
    "# counting clear duplicates\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "exFHq6tt_Zct"
   },
   "outputs": [],
   "source": [
    "# removing obvious duplicates\n",
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-8PuNWQ0_Zct"
   },
   "outputs": [],
   "source": [
    "# checking for duplicates\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can be sure, that our data don't contains obvious duplicates now. But what about implicit duplicates? Let's check column 'genre', are there genres written in different ways but still are the same? Such errors will also affect the result. Let's print a list of unique genre names, sorted in alphabetical order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JIUcqzZN_Zct"
   },
   "outputs": [],
   "source": [
    "# viewing unique genre names\n",
    "df['genre'].sort_values().unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qej-Qmuo_Zct"
   },
   "source": [
    "Looking through the list we can find implicit duplicates of the genre `hiphop`. There are such names as `hip`, `hop` and `hip-hop` that are actually variants of one genre- hiphop. Let's unify all variants, give them the name hiphop and check if we've done everything right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ErNDkmns_Zct"
   },
   "outputs": [],
   "source": [
    "# function for replacing implicit duplicates\n",
    "wrong_genres = ['hip','hop','hip-hop']\n",
    "correct_genre ='hiphop'\n",
    "def replace_wrong_genres(wrong_genres,correct_genre):\n",
    "    for wrong_genre in wrong_genres:\n",
    "        df['genre']= df['genre'].replace(wrong_genre,correct_genre)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YN5i2hpmSo09"
   },
   "outputs": [],
   "source": [
    "# removing implicit duplicates\n",
    "replace_wrong_genres(wrong_genres,correct_genre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wvixALnFG15m"
   },
   "outputs": [],
   "source": [
    "# checking for implicit duplicates\n",
    "sorted(df.genre.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, we did everything right."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ALgNbvF3VtPA"
   },
   "source": [
    "[Back to Contents](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jz6a9-7HQUDd"
   },
   "source": [
    "### Conclusions <a id='data_preprocessing_conclusions'></a>\n",
    "We detected three issues with the data:\n",
    "\n",
    "- Incorrect header styles\n",
    "- Missing values\n",
    "- Obvious and implicit duplicates\n",
    "\n",
    "The headers have been renamed to make processing the data easier.\n",
    "\n",
    "All missing values have been replaced with 'unknown'. But we still have to look whether the missing values in 'genre' will affect our calculations.\n",
    "\n",
    "We have dealt with duplicates. The absence of duplicates will make the results more precise and easier to understand.\n",
    "\n",
    "Now we can move on to testing hypotheses. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eK1es74rVujj"
   },
   "source": [
    "[Back to Contents](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WttZHXH0SqKk"
   },
   "source": [
    "## Stage 3. Testing hypotheses <a id='hypotheses'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Im936VVi_Zcu"
   },
   "source": [
    "### Hypothesis 1: comparing user behavior in two cities <a id='activity'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nwt_MuaL_Zcu"
   },
   "source": [
    "According to the first hypothesis, users from Springfield and Shelbyville listen to music differently. We need to test this thesis using the data on three days of the week: Monday, Wednesday, and Friday. So we will:\n",
    "\n",
    "* Divide the users into groups by city.\n",
    "* Compare how many tracks each group played on Monday, Wednesday, and Friday.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0_Qs96oh_Zcu"
   },
   "outputs": [],
   "source": [
    "# Counting up the tracks played in each city\n",
    "df.groupby(['city'])['track'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dzli3w8o_Zcu"
   },
   "source": [
    "Springfield has more tracks played than Shelbyville. But that does not imply that citizens of Springfield listen to music more often. This city is simply bigger, and there are more users.\n",
    "\n",
    "Now we will group the data by day of the week and find the number of tracks played on Monday, Wednesday, and Friday."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uZMKjiJz_Zcu"
   },
   "outputs": [],
   "source": [
    "# Calculating tracks played on each of the three days\n",
    "df.groupby(['day'])['track'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cC2tNrlL_Zcu"
   },
   "source": [
    "Wednesday is the quietest day overall. But if we consider the two cities separately, we might come to a different conclusion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "POzs8bGa_Zcu"
   },
   "source": [
    "We have seen how grouping by city or day works. Now  we'll write a function that will group by both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Nz3GdQB1_Zcu"
   },
   "outputs": [],
   "source": [
    "# <creating the function number_tracks()>\n",
    "def number_tracks(day,city):\n",
    "    track_list=df[(df['day']==day)&(df['city']==city)]\n",
    "    track_list_count=track_list['user_id'].count()\n",
    "    \n",
    "    return track_list_count\n",
    "number_tracks('Monday','Springfield')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rJcRATNQ_Zcu"
   },
   "outputs": [],
   "source": [
    "# the number of songs played in Springfield on Monday\n",
    "sp_m = number_tracks('Monday','Springfield')\n",
    "sp_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hq_ncZ5T_Zcu"
   },
   "outputs": [],
   "source": [
    "# the number of songs played in Shelbyville on Monday\n",
    "sh_m = number_tracks('Monday','Shelbyville')\n",
    "sh_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_NTy2VPU_Zcu"
   },
   "outputs": [],
   "source": [
    "# the number of songs played in Springfield on Wednesday\n",
    "\n",
    "sp_w = number_tracks('Wednesday','Springfield')\n",
    "sp_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j2y3TAwo_Zcu"
   },
   "outputs": [],
   "source": [
    "# the number of songs played in Shelbyville on Wednesday\n",
    "sh_w = number_tracks('Wednesday','Shelbyville')\n",
    "sh_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vYDw5u_K_Zcu"
   },
   "outputs": [],
   "source": [
    "# the number of songs played in Springfield on Friday\n",
    "sp_f = number_tracks('Friday','Springfield')\n",
    "sp_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8_yzFtW3_Zcu"
   },
   "outputs": [],
   "source": [
    "# the number of songs played in Shelbyville on Friday\n",
    "sh_f = number_tracks('Friday','Shelbyville')\n",
    "sh_f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7QXffbO-_Zcu"
   },
   "source": [
    "For our convenience, let's create one table with the results of our calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "APAcLpOr_Zcu"
   },
   "outputs": [],
   "source": [
    "# table with results\n",
    "dict_option={'city':['Springfield','Shelbyville'],\n",
    "             'monday':[number_tracks('Monday','Springfield'),number_tracks('Monday','Shelbyville')], \n",
    "             'wednesday':[number_tracks('Wednesday','Springfield'),number_tracks('Wednesday','Shelbyville')],\n",
    "             'friday':[number_tracks('Friday','Springfield'),number_tracks('Friday','Shelbyville')],\n",
    "            }\n",
    "tot_dataframe=pd.DataFrame(dict_option)\n",
    "tot_dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-EgPIHYu_Zcu"
   },
   "source": [
    "**Conclusions**\n",
    "\n",
    "The data reveals differences in user behavior:\n",
    "\n",
    "- In Springfield the number of songs were played peaks on Mondays and Fridays, while on Wednesday there is a decrease in activity.\n",
    "- In Shelbyville, on the contrary, users listen to music more on Wednesday. User activity on Monday and Friday is lower.\n",
    "\n",
    "So the first hypothesis seems to be correct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p7nFQajCVw5B"
   },
   "source": [
    "[Back to Contents](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "atZAxtq4_Zcu"
   },
   "source": [
    "### Hypothesis 2: music at the beginning and end of the week <a id='week'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eXrQqXFH_Zcu"
   },
   "source": [
    "According to the second hypothesis, on Monday morning and Friday night, citizens of Springfield listen to genres that differ from ones users from Shelbyville enjoy. Let's create 2 groups of listeners: Springfield residents and Shelbyville residents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qeaFfM_P_Zcu",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# create the spr_general table from the df rows, \n",
    "# where the value in the 'city' column is 'Springfield'\n",
    "spr_general = df[df['city'] == 'Springfield']\n",
    "spr_general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ORaVRKto_Zcu"
   },
   "outputs": [],
   "source": [
    "# create the shel_general from the df rows,\n",
    "# where the value in the 'city' column is 'Shelbyville'\n",
    "shel_general = df[df['city'] == 'Shelbyville']\n",
    "shel_general"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MEJV-CX2_Zcu"
   },
   "source": [
    "Let's create the function that return info on the 15 most popular genres on a given day within the period between the two timestamps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "laJT9BYl_Zcu"
   },
   "outputs": [],
   "source": [
    "def genre_weekday(my_df, day,time1,time2):\n",
    "    \n",
    "    genre_df = my_df[my_df['day'] == day]\n",
    "\n",
    "    \n",
    "    genre_df = genre_df[genre_df['time']<time2]\n",
    "\n",
    "   \n",
    "    genre_df = genre_df[genre_df['time']>time1] # write your code here\n",
    "\n",
    "    genre_df_count = genre_df.groupby(['genre'])['genre'].count()\n",
    "\n",
    "    \n",
    "    genre_df_sorted = genre_df_count.sort_values(ascending=False)\n",
    "  \n",
    "    return genre_df_sorted[:15]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result = genre_weekday(df,'Monday','07:00:00','11:00:00')\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "la2s2_PF_Zcu"
   },
   "source": [
    "Compare the results of the `genre_weekday()` function for Springfield and Shelbyville on Monday morning (from 7AM to 11AM) and on Friday evening (from 17:00 to 23:00):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yz7itPUQ_Zcu"
   },
   "outputs": [],
   "source": [
    "# calling the function for Monday morning in Springfield (use spr_general instead of the df table)\n",
    "spr_mon = genre_weekday(spr_general,'Monday','07:00:00','11:00:00')\n",
    "spr_mon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kwUcHPdy_Zcu"
   },
   "outputs": [],
   "source": [
    "# calling the function for Monday morning in Shelbyville (use shel_general instead of the df table)\n",
    "shel_mon = genre_weekday(shel_general,'Monday','07:00:00','11:00:00')\n",
    "shel_mon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EzXVRE1o_Zcu"
   },
   "outputs": [],
   "source": [
    "# calling the function for Friday evening in Springfield\n",
    "spr_fr = genre_weekday(spr_general,'Friday','17:00:00','23:00:00')\n",
    "spr_fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JZaEKu5v_Zcu"
   },
   "outputs": [],
   "source": [
    "# calling the function for Friday evening in Shelbyville\n",
    "shel_fr = genre_weekday(shel_general,'Friday','17:00:00','23:00:00')\n",
    "shel_fr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wrCe4MNX_Zcu"
   },
   "source": [
    "**Conclusion**\n",
    "\n",
    "Having compared the top 15 genres on Monday morning, we can draw the following conclusions:\n",
    "\n",
    "1. Users from Springfield and Shelbyville listen to similar music. The top five genres are the same, only rock and electronic have switched places.\n",
    "\n",
    "2. In Springfield the number of missing values turned out to be so big that the value `'unknown'` came in 10th place. This means that missing values make up a considerable portion of the data, which may be a basis for questioning the reliability of our conclusions.\n",
    "\n",
    "For Friday evening, the situation is similar. Individual genres vary, but in general, the top 15 is similar for the both cities.\n",
    "\n",
    "Thus, the second hypothesis has been reguted:\n",
    "* Users listen to similar music at the beginning and the end of the week.\n",
    "* There is no big difference between Springfield and Shelbyville. In both cities, pop is the most popular genre.\n",
    "\n",
    "However, the number of missing values makes this result questionable. In Springfield, there are so many that they affect our top 15. If we don't have these missing values, things might look different."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jLmXgdanVyhP"
   },
   "source": [
    "[Back to Contents](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JolODAqr_Zcu"
   },
   "source": [
    "### Hypothesis 3: genre preferences in Springfield and Shelbyville <a id='genre'></a>\n",
    "\n",
    "Hypothesis: Shelbyville loves rap music. Springfield's citizens are more into pop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r19lIPke_Zcu"
   },
   "outputs": [],
   "source": [
    "# on one line: group the spr_general table by the 'genre' column, \n",
    "# count the 'genre' values with count() in the grouping, \n",
    "# sort the resulting Series in descending order, and store it to spr_genres\n",
    "spr_genres = spr_general.groupby(['genre'])['track'].count()\n",
    "spr_genres = spr_genres.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WhCSooF8_Zcv"
   },
   "outputs": [],
   "source": [
    "# printing the first 10 rows of spr_genres\n",
    "spr_genres.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gluLIpE7_Zcv"
   },
   "outputs": [],
   "source": [
    "# on one line: group the shel_general table by the 'genre' column, \n",
    "# count the 'genre' values in the grouping with count(), \n",
    "# sort the resulting Series in descending order and store it to shel_genres\n",
    "shel_generes = shel_general.groupby(['genre'])['track'].count()\n",
    "shel_generes = shel_generes.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uaGJHjVU_Zcv"
   },
   "outputs": [],
   "source": [
    "# printing the first 10 rows from shel_genres\n",
    "shel_generes.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RY51YJYu_Zcv"
   },
   "source": [
    "**Conclusion**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nVhnJEm__Zcv"
   },
   "source": [
    "The hypothesis has been partially proven true:\n",
    "* Pop music is the most popular genre in Springfield, as expected.\n",
    "* However, pop music turned out to be equally popular in Springfield and Shelbyville. Rap wasn't in the top 5 for Springfield's citizens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Byr0RfpPVz14"
   },
   "source": [
    "[Back to Contents](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ykKQ0N65_Zcv"
   },
   "source": [
    "# Findings <a id='end'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tjUwbHb3_Zcv"
   },
   "source": [
    "We have tested the following three hypotheses:\n",
    "\n",
    "1. User activity differs depending on the day of the week and from city to city. \n",
    "2. On Monday mornings, Springfield and Shelbyville residents listen to different genres. This is also true for Friday evenings. \n",
    "3. Springfield and Shelbyville listeners have different music preferences. \n",
    "\n",
    "After analyzing the data, we concluded:\n",
    "\n",
    "1. User activity in Springfield and Shelbyville depends on the day of the week. In Springfield people listen to music more on \n",
    "Mondays and Fridays,in Shelbyville, on the contrary, users listen to music more on Wednesdays. \n",
    "The first hypothesis is fully accepted.\n",
    "\n",
    "2. Musical preferences do not vary significantly over the day of the week in both Springfield and Shelbyville. In Springfield \n",
    "and Shelbyville people listen to pop music the most.\n",
    "    So we can't accept this hypothesis. We must also keep in mind that the result could have been different if there were no\n",
    "    missing values.\n",
    "\n",
    "3. It turns out that the musical preferences of users from Springfield and Shelbyville are quite similar.\n",
    "The third hypothesis is rejected. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ju4AHDSgV1FE"
   },
   "source": [
    "[Back to Contents](#back)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "E0vqbgi9ay0H",
    "VUC88oWjTJw2",
    "atZAxtq4_Zcu"
   ],
   "name": "EmptyFinalProject.ipynb\"",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
